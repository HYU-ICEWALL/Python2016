{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python으로 웹툰 파싱하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요한 패키지들을 가져옵니다.\n",
    "bs4는 BeautifulSoup로 좀 더 간편하게 파싱을 도와줍니다.\n",
    "lxml은 beautifulsoup와 같이 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen\n",
    "# from urllib import urlopen -for- python <= 2.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터를 가져옵니다\n",
    "url에 request를 날려서 파싱할 데이터를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 이 코드는 다른 요일의 웹툰 목록도 확인해보고 싶을때 사용할 수 있습니다.\n",
    "weeks = ['mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun']\n",
    "week = weeks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = urlopen('http://comic.naver.com/webtoon/weekdayList.nhn?week=' + week)\n",
    "raw = bs(res, 'lxml')\n",
    "res.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹툰 목록을 담고있는 div를 가져옵니다.\n",
    "웹툰이 들어있는 `div`들을 잘 살펴보면 모든 웹툰 목록을 감싸는 `div`는 아래의 `div`입니다.\n",
    "```\n",
    "<div class=\"list_area daily_img\">\n",
    "```\n",
    "따라서 class이름이 list_area인것을 골라옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "div = raw.body.findAll('div', {'class': 'list_area'})[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 웹툰을 가져오기\n",
    "`<li>`태그가 웹툰 하나를 감싸고 있는것을 확인할 수 있습니다.\n",
    "\n",
    "따라서 위에서 구한 div에서 li들을 모두 찾으면 각 웹툰 정보를 감싸는 li태그들이 담긴 리스트를 반환받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toons = div.findAll('li')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 웹툰정보에서 이름만 가져오기\n",
    "이제 각 줄을 반복하면서 이름을 가져오면 됩니다.\n",
    "\n",
    "웹툰 이름은 `li`태그 안에 `dl`태그 안에 `dt`태그 안에 `a`태그로 감싸져 있는 것을 알 수 있습니다.\n",
    "이렇게 하나하나 접근해도 되지만 너무 귀찮고 `li`태그안에 `dt`태그가 여럿 있지 않으므로 바로 `dt`태그로 가져오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대학일기\n",
      "신의 탑\n",
      "뷰티풀 군바리\n",
      "소녀의 세계\n",
      "평범한 8반\n",
      "마이너스의 손\n",
      "여중생A\n",
      "썸남\n",
      "윈드브레이커\n",
      "이상하고 아름..\n",
      "윈터우즈\n",
      "MZ\n",
      "하루 3컷\n",
      "부부생활\n",
      "가우스전자 시..\n",
      "첩보의 별\n",
      "203호 저승..\n",
      "생활의참견\n",
      "탈(TAL)\n",
      "팀피닉스\n",
      "크리퍼스큘\n",
      "3P\n",
      "동토의 여명\n",
      "히어로메이커\n",
      "나의 인생샷을..\n"
     ]
    }
   ],
   "source": [
    "for toon in toons:\n",
    "    dt = toon.findAll('dt')[0]\n",
    "    print (dt.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
